#!/usr/bin/env python3
"""
Retention enforcer for CSV export cleanup.

This script manages the retention policy for CSV exports generated by the
open banking MCP tools. It can clean up old CSV files based on configurable
retention periods.
"""

import os
import sys
import glob
import time
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Any
import json


class RetentionEnforcer:
    """Manages CSV file retention and cleanup."""

    def __init__(self, base_directory: str = ".", retention_days: int = 30):
        """
        Initialize the retention enforcer.

        Args:
            base_directory: Directory to search for CSV files
            retention_days: Number of days to retain CSV files
        """
        self.base_directory = base_directory
        self.retention_days = retention_days
        self.retention_threshold = datetime.now() - timedelta(days=retention_days)

    def find_csv_files(self) -> List[str]:
        """Find all CSV files in the base directory."""
        csv_patterns = [
            "*.csv",
            "hmrc_export_*.csv",
            "test_*.csv"
        ]

        csv_files = []
        for pattern in csv_patterns:
            full_pattern = os.path.join(self.base_directory, pattern)
            csv_files.extend(glob.glob(full_pattern))

        return csv_files

    def get_file_age(self, file_path: str) -> datetime:
        """Get the creation/modification time of a file."""
        try:
            # Use modification time as a proxy for creation time
            timestamp = os.path.getmtime(file_path)
            return datetime.fromtimestamp(timestamp)
        except OSError as e:
            print(f"‚ö†Ô∏è Could not get file age for {file_path}: {e}")
            return datetime.min

    def is_file_old(self, file_path: str) -> bool:
        """Check if a file is older than the retention threshold."""
        file_age = self.get_file_age(file_path)
        return file_age < self.retention_threshold

    def analyze_csv_files(self) -> Dict[str, Any]:
        """Analyze CSV files and categorize them by age."""
        csv_files = self.find_csv_files()

        analysis = {
            "total_files": len(csv_files),
            "old_files": [],
            "recent_files": [],
            "retention_threshold": self.retention_threshold.isoformat(),
            "retention_days": self.retention_days
        }

        for file_path in csv_files:
            file_info = {
                "path": file_path,
                "filename": os.path.basename(file_path),
                "size_bytes": os.path.getsize(file_path) if os.path.exists(file_path) else 0,
                "modified_time": self.get_file_age(file_path).isoformat(),
                "is_old": False
            }

            if self.is_file_old(file_path):
                file_info["is_old"] = True
                analysis["old_files"].append(file_info)
            else:
                analysis["recent_files"].append(file_info)

        return analysis

    def cleanup_old_files(self, dry_run: bool = True) -> Dict[str, Any]:
        """
        Clean up old CSV files.

        Args:
            dry_run: If True, only report what would be deleted without actually deleting

        Returns:
            Dictionary with cleanup results
        """
        analysis = self.analyze_csv_files()
        old_files = analysis["old_files"]

        results = {
            "dry_run": dry_run,
            "files_processed": len(old_files),
            "files_deleted": 0,
            "errors": [],
            "deleted_files": []
        }

        total_size_freed = 0

        for file_info in old_files:
            file_path = file_info["path"]
            file_size = file_info["size_bytes"]

            try:
                if not dry_run:
                    os.remove(file_path)
                    results["files_deleted"] += 1
                    results["deleted_files"].append({
                        "path": file_path,
                        "size_bytes": file_size,
                        "deleted_at": datetime.now().isoformat()
                    })
                    total_size_freed += file_size
                    print(f"üóëÔ∏è Deleted: {file_path} ({file_size} bytes)")
                else:
                    print(f"üìã Would delete: {file_path} ({file_size} bytes)")
                    results["files_deleted"] += 1

            except OSError as e:
                error_msg = f"Failed to delete {file_path}: {e}"
                results["errors"].append(error_msg)
                print(f"‚ùå {error_msg}")

        results["total_size_freed_bytes"] = total_size_freed
        results["total_size_freed_mb"] = round(total_size_freed / (1024 * 1024), 2)

        return results

    def test_deletion(self) -> bool:
        """
        Test deletion functionality by creating and deleting a temporary file.

        Returns:
            True if deletion test passes, False otherwise
        """
        test_filename = "retention_test_file.tmp"
        test_path = os.path.join(self.base_directory, test_filename)

        try:
            # Create test file
            with open(test_path, 'w') as f:
                f.write("Test file for retention enforcer\n")
                f.write(f"Created at: {datetime.now().isoformat()}\n")

            print(f"‚úÖ Created test file: {test_path}")

            # Wait a moment
            time.sleep(0.1)

            # Delete test file
            os.remove(test_path)
            print(f"‚úÖ Deleted test file: {test_path}")

            return True

        except Exception as e:
            print(f"‚ùå Deletion test failed: {e}")
            # Clean up test file if it exists
            if os.path.exists(test_path):
                try:
                    os.remove(test_path)
                except:
                    pass
            return False

    def generate_report(self) -> str:
        """Generate a human-readable retention report."""
        analysis = self.analyze_csv_files()

        report = f"""
CSV File Retention Report
========================
Generated: {datetime.now().isoformat()}
Base Directory: {self.base_directory}
Retention Period: {self.retention_days} days
Retention Threshold: {analysis['retention_threshold']}

Summary:
--------
Total CSV files found: {analysis['total_files']}
Files older than retention period: {len(analysis['old_files'])}
Recent files: {len(analysis['recent_files'])}

Old Files (candidates for deletion):
-----------------------------------
"""

        if analysis['old_files']:
            for file_info in analysis['old_files']:
                report += f"- {file_info['filename']} ({file_info['size_bytes']} bytes, modified: {file_info['modified_time']})\n"
        else:
            report += "No old files found.\n"

        report += f"""
Recent Files (within retention period):
-------------------------------------
"""

        if analysis['recent_files']:
            for file_info in analysis['recent_files']:
                report += f"- {file_info['filename']} ({file_info['size_bytes']} bytes, modified: {file_info['modified_time']})\n"
        else:
            report += "No recent files found.\n"

        return report


def main():
    """Main entry point for the retention enforcer."""
    parser = argparse.ArgumentParser(
        description="CSV file retention enforcer for open banking MCP exports",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s --analyze                    # Analyze files without deleting
  %(prog)s --cleanup --dry-run          # Show what would be deleted
  %(prog)s --cleanup                    # Actually delete old files
  %(prog)s --test-deletion              # Test deletion functionality
  %(prog)s --retention-days 7 --cleanup # Use 7-day retention period
        """
    )

    parser.add_argument(
        "--base-directory", "-d",
        default=".",
        help="Base directory to search for CSV files (default: current directory)"
    )

    parser.add_argument(
        "--retention-days", "-r",
        type=int,
        default=30,
        help="Number of days to retain CSV files (default: 30)"
    )

    parser.add_argument(
        "--analyze", "-a",
        action="store_true",
        help="Analyze CSV files and show retention report"
    )

    parser.add_argument(
        "--cleanup", "-c",
        action="store_true",
        help="Clean up old CSV files"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be deleted without actually deleting (use with --cleanup)"
    )

    parser.add_argument(
        "--test-deletion", "-t",
        action="store_true",
        help="Test deletion functionality"
    )

    parser.add_argument(
        "--json-output", "-j",
        action="store_true",
        help="Output results in JSON format"
    )

    args = parser.parse_args()

    # Initialize retention enforcer
    enforcer = RetentionEnforcer(args.base_directory, args.retention_days)

    # Handle different operations
    if args.test_deletion:
        print("üß™ Testing deletion functionality...")
        success = enforcer.test_deletion()
        if success:
            print("‚úÖ Deletion test passed!")
            sys.exit(0)
        else:
            print("‚ùå Deletion test failed!")
            sys.exit(1)

    elif args.analyze:
        print("üìä Analyzing CSV files...")
        analysis = enforcer.analyze_csv_files()

        if args.json_output:
            print(json.dumps(analysis, indent=2))
        else:
            report = enforcer.generate_report()
            print(report)

    elif args.cleanup:
        dry_run = args.dry_run
        action = "Dry run cleanup" if dry_run else "Cleanup"
        print(f"üßπ {action} of old CSV files...")

        results = enforcer.cleanup_old_files(dry_run=dry_run)

        if args.json_output:
            print(json.dumps(results, indent=2))
        else:
            print(f"\nCleanup Results:")
            print(f"Files processed: {results['files_processed']}")
            print(f"Files {'would be ' if dry_run else ''}deleted: {results['files_deleted']}")
            print(f"Total size freed: {results['total_size_freed_mb']} MB")

            if results['errors']:
                print(f"\nErrors encountered:")
                for error in results['errors']:
                    print(f"- {error}")

    else:
        # Default: show analysis
        print("üìä Analyzing CSV files...")
        analysis = enforcer.analyze_csv_files()
        report = enforcer.generate_report()
        print(report)


if __name__ == "__main__":
    main()
